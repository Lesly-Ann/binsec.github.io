---
layout: post
title:  "LPAR '18: extended abstract" 
date:   2019-04-04
categories: conference paper abstract
paper-title: "Arrays Made Simpler: An Efficient, Scalable and Thorough Preprocessing"
topic: "Constraint preprocessing for efficient Symbolic Execution"
pdf: http://sebastien.bardin.free.fr/2018-lpar.pdf
---


## Motivation 

Automatic decision procedures for Satisfiability Modulo Theory are at the heart
of almost all recent formal verificpfcation methods, including Symbolic Execution
(SE). Especially, the theory of arrays enjoys a central position in software
verification as it allows to model memory or essential data structures such as
maps, vectors and hash tables.

However, this theory is known to be hard to solve in both theory and practice.
Even more so in the case of very long formulas coming from unrolling-based
verification methods. Standard simplification techniques à la Read-over-Write (RoW)
have two main drawbacks: 

- they do not scale on very long sequences of stores and 
- they miss many simplification opportunities because of a crude syntactic
  (dis-)equality reasoning. 


Yet, this is not satisfactory when considering very long chains of writes, as
can be encountered in unfolding-based verification techniques such as SE or
Bounded Model checking — the case of Deductive Verification is different since
user-defined invariants prevent the unfolding. The theory of arrays can then
quickly become a bottleneck of constraint solving. Especially, the
RoW-simplification step is often very limited, for two
reasons. 

1. Exploring for every read in a backward manner the corresponding list of all
writes yields a quadratic time cost (in the number of array 
operations) and therefore it does not scale to very long formulas. 

    This is a major issue in practice: for example, Symbolic Execution over
    malware or obfuscated programs may need to consider execution traces of
    several millions of instructions. The generated formulas have several
    hundreds of thousands of array operations. Bounding the
    backward exploration is not enough for it misses too many RoW-simplifications.

2. (dis)-equalities can be rarely decided during
preprocessing as standard methods rely on efficient but crude approximate
equality checks (typically, syntactic term equality), limiting again the power
of these approaches. With such checks, index equality may be sometimes proven,
but disequality can never be — except in the very restricted case of
constant-value indexes.


fca## Contributions

This papers presents novel approach to RoW-simplification named FAS (Fast Array
Simplification). Its goal is to allow to scale and to simplify much more RoW
than previous approaches FAS has 3 key components:

- dedicated data structure;
- base normalization;
- domain reasoning.

Experimental results demonstrate that fas scales over very large formulas (several hundreds of
thousands of RoW) typically coming from Symbolic Execution and can yield very significant
gains in terms of runtime — possibly passing from hours to seconds.

Our experiments on FAS in different settings for three leading SMT solvers show
that this technique is fast and scalable: the number of RoWs is always
significantly reduced, which in turns impacts positively the resolution times.
On big formulas (millions of array accesses) generated by Symbolic Execution,
the reduction is drastic: it can go as far as condensing a day-long resolution
into minutes.


